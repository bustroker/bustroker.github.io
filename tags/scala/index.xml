<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Scala on Coding notes - and snippets</title>
    <link>https://www.bustroker.com/tags/scala/</link>
    <description>Recent content in Scala on Coding notes - and snippets</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 24 Jan 2022 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://www.bustroker.com/tags/scala/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Running Concurrent Tasks with Scala Futures</title>
      <link>https://www.bustroker.com/notes/running-concurrent-tasks-with-scala-futures/</link>
      <pubDate>Mon, 24 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://www.bustroker.com/notes/running-concurrent-tasks-with-scala-futures/</guid>
      <description>Goal Execute multiple tasks concurrently using Scala Futures and wait for their completion.&#xA;Setup scalaVersion := &amp;#34;2.13.6&amp;#34; // Also supports 2.12.x Implementation import scala.concurrent._ import scala.concurrent.duration._ import scala.concurrent.ExecutionContext.Implicits.global object Application extends App { def writeStuff(step: Int, max: Int, name: String) = { for(i &amp;lt;- 1 to max){ Thread.sleep(step*1000) println(s&amp;#34;task $name =&amp;gt; $i s&amp;#34;) } } val futureTask1 = Future { writeStuff(1, 10, &amp;#34;la primera&amp;#34;) } val futureTask2 = Future { writeStuff(2, 8, &amp;#34;la segunda&amp;#34;) } val futures: List[Future[Unit]] = List(futureTask1, futureTask2) futures.</description>
    </item>
    <item>
      <title>Spark with Scala and Azure Storage</title>
      <link>https://www.bustroker.com/notes/spark-with-scala-and-azure-storage/</link>
      <pubDate>Mon, 20 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://www.bustroker.com/notes/spark-with-scala-and-azure-storage/</guid>
      <description>Goal Set up a Spark project in Scala that reads from Azure Blob Storage and writes to Azure Data Lake Storage Gen2.&#xA;Dependencies ThisBuild / version := &amp;#34;0.1.0&amp;#34; ThisBuild / scalaVersion := &amp;#34;2.12.13&amp;#34; ThisBuild / organization := &amp;#34;bkr&amp;#34; lazy val KafkaStreamProcessing = (project in file(&amp;#34;.&amp;#34;)) .settings( name := &amp;#34;Bkr.Spark&amp;#34;, libraryDependencies += &amp;#34;org.apache.spark&amp;#34; %% &amp;#34;spark-core&amp;#34; % &amp;#34;3.1.1&amp;#34;, libraryDependencies += &amp;#34;org.apache.spark&amp;#34; %% &amp;#34;spark-sql&amp;#34; % &amp;#34;3.1.1&amp;#34;, libraryDependencies += &amp;#34;org.apache.spark&amp;#34; %% &amp;#34;spark-sql-kafka-0-10&amp;#34; % &amp;#34;3.1.1&amp;#34;, libraryDependencies += &amp;#34;org.</description>
    </item>
    <item>
      <title>Writing to Delta Lake from Spark with Scala</title>
      <link>https://www.bustroker.com/notes/writing-to-delta-lake-from-spark-with-scala/</link>
      <pubDate>Mon, 20 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://www.bustroker.com/notes/writing-to-delta-lake-from-spark-with-scala/</guid>
      <description>Goal Process JSON operations (create/update) and write the final snapshot to Delta Lake on Azure Data Lake Storage.&#xA;Dependencies ThisBuild / version := &amp;#34;0.1.0&amp;#34; ThisBuild / scalaVersion := &amp;#34;2.13.8&amp;#34; ThisBuild / organization := &amp;#34;bkr&amp;#34; libraryDependencies ++= List(&amp;#34;org.apache.spark&amp;#34; %% &amp;#34;spark-core&amp;#34; % &amp;#34;3.2.0&amp;#34;, &amp;#34;org.apache.spark&amp;#34; %% &amp;#34;spark-sql&amp;#34; % &amp;#34;3.2.0&amp;#34;, &amp;#34;org.apache.spark&amp;#34; %% &amp;#34;spark-sql-kafka-0-10&amp;#34; % &amp;#34;3.2.0&amp;#34;, &amp;#34;org.apache.spark&amp;#34; %% &amp;#34;spark-avro&amp;#34; % &amp;#34;3.2.0&amp;#34;) libraryDependencies ++= List(&amp;#34;org.apache.hadoop&amp;#34; % &amp;#34;hadoop-common&amp;#34; % &amp;#34;3.3.1&amp;#34;, &amp;#34;org.apache.hadoop&amp;#34; % &amp;#34;hadoop-azure&amp;#34; % &amp;#34;3.3.1&amp;#34;) libraryDependencies += &amp;#34;org.</description>
    </item>
    <item>
      <title>Scala HTTP API with http4s</title>
      <link>https://www.bustroker.com/notes/scala-http-api-with-http4s/</link>
      <pubDate>Sat, 18 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://www.bustroker.com/notes/scala-http-api-with-http4s/</guid>
      <description>Goal Create a minimal HTTP API server in Scala using http4s.&#xA;Setup Add dependencies to build.sbt:&#xA;scalaVersion := &amp;#34;2.13.6&amp;#34; // Also supports 2.12.x val http4sVersion = &amp;#34;0.23.1&amp;#34; // Only necessary for SNAPSHOT releases resolvers += Resolver.sonatypeRepo(&amp;#34;snapshots&amp;#34;) libraryDependencies ++= Seq( &amp;#34;org.http4s&amp;#34; %% &amp;#34;http4s-dsl&amp;#34; % http4sVersion, &amp;#34;org.http4s&amp;#34; %% &amp;#34;http4s-blaze-server&amp;#34; % http4sVersion, &amp;#34;org.http4s&amp;#34; %% &amp;#34;http4s-blaze-client&amp;#34; % http4sVersion ) Implementation Create Server.scala:&#xA;package bkr.joker.webapi import cats.effect._ import org.http4s.blaze.server._ import scala.concurrent.ExecutionContext.global // import cats.effect._ import org.</description>
    </item>
    <item>
      <title>Scala Up and Running</title>
      <link>https://www.bustroker.com/notes/scala-up-and-running/</link>
      <pubDate>Wed, 05 May 2021 00:00:00 +0000</pubDate>
      <guid>https://www.bustroker.com/notes/scala-up-and-running/</guid>
      <description>Goal Set up a Scala development environment and create a working project with SBT, including configuration management, testing, and packaging.&#xA;Installation Java ## Install AdoptOpenJDK 11 ## Other JDK distributions may fail at runtime with HTTPS issues Scala ## Install SBT from official site sbt scalaVersion Project Setup Structure root/ ├── build.sbt ├── project/ │ └── plugins.sbt └── src/ ├── main/ │ ├── resources/ │ │ └── app.conf │ └── scala/bkr/data/spark/ │ ├── App.</description>
    </item>
  </channel>
</rss>
