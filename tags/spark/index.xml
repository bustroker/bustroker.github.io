<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>spark on Coding notes</title>
    <link>https://www.bustroker.com/tags/spark/</link>
    <description>Recent content in spark on Coding notes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 15 Aug 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://www.bustroker.com/tags/spark/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Run Jupyter notebook with spark in docker</title>
      <link>https://www.bustroker.com/notes/run-jupyter-notebook-with-spark-in-docker/</link>
      <pubDate>Sun, 15 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.bustroker.com/notes/run-jupyter-notebook-with-spark-in-docker/</guid>
      <description>Install spark to run locally docker run -p 8888:8888 -p 4041:4041 jupyter/all-spark-notebook The auth token is logged in the terminal. Copy it. In host browse to localhost:8888. Use the token to authenticate in the interface.
Create new spylon-kernel notebook and write scala code.
Spark WebUI is running on port 4041</description>
    </item>
    
    <item>
      <title>Install spark and hadoop in Windows 10</title>
      <link>https://www.bustroker.com/notes/install-spark-and-hadoop-in-windows-10/</link>
      <pubDate>Thu, 12 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.bustroker.com/notes/install-spark-and-hadoop-in-windows-10/</guid>
      <description>Install spark to run locally Versions  Java  java -versionopenjdk version &amp;quot;1.8.0_292&amp;quot;OpenJDK Runtime Environment (AdoptOpenJDK)(build 1.8.0_292-b10)OpenJDK 64-Bit Server VM (AdoptOpenJDK)(build 25.292-b10, mixed mode) Scala  sbtconsoleWelcome to Scala 2.12.13 (OpenJDK 64-Bit Server VM, Java 1.8.0_292).Install Spark Download from https://spark.apache.org/downloads.html.
Spark release 3.1.2 with hadoop2.7 folder downloaded and copied to C:\Spark\spark-3.1.2-bin-hadoop2.7.
Add C:\Spark\spark-3.1.2-bin-hadoop2.7 to user&amp;rsquo;s PATH
Install Hadoop Downloaded from https://github.com/cdarlint/winutils hadoop-2.7.7 folder downloaded and placed in C:\Hadoop\hadoop-2.</description>
    </item>
    
  </channel>
</rss>
